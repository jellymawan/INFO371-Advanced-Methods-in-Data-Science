{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc4b28d7-0e52-4085-a57f-d7f8f3b6f540",
   "metadata": {},
   "source": [
    "# Bayes-Theorem based Spam Filter\n",
    "\n",
    "## Ling-Spam emails\n",
    "\n",
    "### 1 Explore and clean the data\n",
    "\n",
    "#### 1. Load the lingspam-emails.csv.bz2 dataset.\n",
    "\n",
    "Browse a handful of emails, both spam and non-spam ones, to see what kind of text we are working\n",
    "with here.\n",
    "\n",
    "Hint: check out textwrap module to print long strings on multiple lines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "160e7e9c-988a-408f-896e-89a6fe2ac2be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>files</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>3-1msg1.txt</td>\n",
       "      <td>Subject: re : 2 . 882 s - &gt; np np  &gt; date : su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>3-1msg2.txt</td>\n",
       "      <td>Subject: s - &gt; np + np  the discussion of s - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>3-1msg3.txt</td>\n",
       "      <td>Subject: 2 . 882 s - &gt; np np  . . . for me it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>3-375msg1.txt</td>\n",
       "      <td>Subject: gent conference  \" for the listserv \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>3-378msg1.txt</td>\n",
       "      <td>Subject: query : causatives in korean  could a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2888</th>\n",
       "      <td>True</td>\n",
       "      <td>spmsgc50.txt</td>\n",
       "      <td>Subject: .  international driver ' s license n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2889</th>\n",
       "      <td>True</td>\n",
       "      <td>spmsgc51.txt</td>\n",
       "      <td>Subject: new on 95 . 8 capital fm  this is new...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2890</th>\n",
       "      <td>True</td>\n",
       "      <td>spmsgc52.txt</td>\n",
       "      <td>Subject: re : new medical technology  company ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2891</th>\n",
       "      <td>True</td>\n",
       "      <td>spmsgc53.txt</td>\n",
       "      <td>Subject: re : your request for an overview  ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>True</td>\n",
       "      <td>spmsgc54.txt</td>\n",
       "      <td>Subject: new on capital fm  this is new at htt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2893 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       spam          files                                            message\n",
       "0     False    3-1msg1.txt  Subject: re : 2 . 882 s - > np np  > date : su...\n",
       "1     False    3-1msg2.txt  Subject: s - > np + np  the discussion of s - ...\n",
       "2     False    3-1msg3.txt  Subject: 2 . 882 s - > np np  . . . for me it ...\n",
       "3     False  3-375msg1.txt  Subject: gent conference  \" for the listserv \"...\n",
       "4     False  3-378msg1.txt  Subject: query : causatives in korean  could a...\n",
       "...     ...            ...                                                ...\n",
       "2888   True   spmsgc50.txt  Subject: .  international driver ' s license n...\n",
       "2889   True   spmsgc51.txt  Subject: new on 95 . 8 capital fm  this is new...\n",
       "2890   True   spmsgc52.txt  Subject: re : new medical technology  company ...\n",
       "2891   True   spmsgc53.txt  Subject: re : your request for an overview  ye...\n",
       "2892   True   spmsgc54.txt  Subject: new on capital fm  this is new at htt...\n",
       "\n",
       "[2893 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "raw = pd.read_csv(\"../data/lingspam-emails.csv.bz2\", sep=\"\\t\")\n",
    "np.shape(raw)\n",
    "#pd.set_option(\"display.max_colwidth\", -1) # uncomment to see all the text\n",
    "raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db32f0e-2f5c-486b-8c6d-e33ece343c49",
   "metadata": {},
   "source": [
    "#### 2. Ensure the data is clean: remove all cases with missing spam and empty message field. We do not care about the file names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "511a46f7-e242-4c9a-a2a1-cbcaeac5a9f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spam       0\n",
       "files      0\n",
       "message    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls = raw.dropna(subset=[\"spam\", \"message\"])\n",
    "ls.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b296051-e814-4997-b257-eda761eeaffe",
   "metadata": {},
   "source": [
    "### 2 Create Document-term matrix (DTM)\n",
    "\n",
    "#### 1. Choose ∼ 10 words which might be good to distinguish between spam/non-spam. Use these four: viagra, deadline, million, and and. Choose more words yourself (you may want to return here and reconsider your choice later).\n",
    "\n",
    "We chose: rates, sex, cash, insurance, free, and money"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3212bfe5-5ee8-4c74-9a95-734580b87ba1",
   "metadata": {},
   "source": [
    "#### 2. Convert your messages into DTM. We do not use the full 60k-words DTM here but only a baby-DTM of the 10 words you picked above. You may add the DTM columns to the original data frame, or keep those in a separate structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b110e04-1629-4590-b5ea-b4a1dfbc34ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>files</th>\n",
       "      <th>message</th>\n",
       "      <th>viagra</th>\n",
       "      <th>deadline</th>\n",
       "      <th>million</th>\n",
       "      <th>and</th>\n",
       "      <th>toll</th>\n",
       "      <th>prizes</th>\n",
       "      <th>cash</th>\n",
       "      <th>insurance</th>\n",
       "      <th>free</th>\n",
       "      <th>money</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>3-1msg1.txt</td>\n",
       "      <td>Subject: re : 2 . 882 s - &gt; np np  &gt; date : su...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>3-1msg2.txt</td>\n",
       "      <td>Subject: s - &gt; np + np  the discussion of s - ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>3-1msg3.txt</td>\n",
       "      <td>Subject: 2 . 882 s - &gt; np np  . . . for me it ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>3-375msg1.txt</td>\n",
       "      <td>Subject: gent conference  \" for the listserv \"...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>3-378msg1.txt</td>\n",
       "      <td>Subject: query : causatives in korean  could a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>3-378msg2.txt</td>\n",
       "      <td>Subject: l2 learning / cultural empathy  a gra...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>3-378msg3.txt</td>\n",
       "      <td>Subject: psycholinguistics teaching  for an un...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>False</td>\n",
       "      <td>3-378msg4.txt</td>\n",
       "      <td>Subject: german corpora  i am looking for on-l...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>False</td>\n",
       "      <td>3-378msg5.txt</td>\n",
       "      <td>Subject: t  hi , help ! i have to design an ex...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>False</td>\n",
       "      <td>3-379msg1.txt</td>\n",
       "      <td>Subject: job - university of utah  the linguis...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    spam          files                                            message  \\\n",
       "0  False    3-1msg1.txt  Subject: re : 2 . 882 s - > np np  > date : su...   \n",
       "1  False    3-1msg2.txt  Subject: s - > np + np  the discussion of s - ...   \n",
       "2  False    3-1msg3.txt  Subject: 2 . 882 s - > np np  . . . for me it ...   \n",
       "3  False  3-375msg1.txt  Subject: gent conference  \" for the listserv \"...   \n",
       "4  False  3-378msg1.txt  Subject: query : causatives in korean  could a...   \n",
       "5  False  3-378msg2.txt  Subject: l2 learning / cultural empathy  a gra...   \n",
       "6  False  3-378msg3.txt  Subject: psycholinguistics teaching  for an un...   \n",
       "7  False  3-378msg4.txt  Subject: german corpora  i am looking for on-l...   \n",
       "8  False  3-378msg5.txt  Subject: t  hi , help ! i have to design an ex...   \n",
       "9  False  3-379msg1.txt  Subject: job - university of utah  the linguis...   \n",
       "\n",
       "   viagra  deadline  million  and  toll  prizes  cash  insurance  free  money  \n",
       "0       0         0        0    1     0       0     0          0     0      0  \n",
       "1       0         0        0    0     0       0     0          0     0      0  \n",
       "2       0         0        0    0     0       0     0          0     0      0  \n",
       "3       0         0        0    1     0       0     0          0     0      1  \n",
       "4       0         0        0    1     0       0     0          0     0      0  \n",
       "5       0         0        0    1     0       0     0          0     0      0  \n",
       "6       0         0        0    1     0       0     0          0     0      0  \n",
       "7       0         0        0    0     0       0     0          0     0      0  \n",
       "8       0         0        0    1     0       0     0          0     0      0  \n",
       "9       0         0        0    1     0       0     0          0     0      0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_words = [\"viagra\", \"deadline\", \"million\", \"and\", \"toll\", \"prizes\", \"cash\", \"insurance\", \"free\", \"money\"]\n",
    "\n",
    "for w in list_of_words:\n",
    "    ls[w] = ls.message.str.lower().str.contains(w)\n",
    "    ls[w] = ls[w] * 1 #1 = true, 0 = false\n",
    "    \n",
    "ls.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f046ece-3b7c-4463-86a4-689a8d4518f3",
   "metadata": {},
   "source": [
    "#### 3. Split your work data (i.e. the DTM) and target (the spam indicator) into training and validation chunks (80/20 is a good split).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ca11354-5fef-41cf-a0f5-4c660dc1276d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ls.drop([\"spam\", \"files\", \"message\"], axis=1)\n",
    "y = ls.spam * 1\n",
    "train_X, test_X, train_y, test_y = train_test_split(x,y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5dd5b59-9c9e-444f-bf49-9a1d1d5f681d",
   "metadata": {},
   "source": [
    "### 3. Estimate and validate\n",
    "\n",
    "#### 1. Design a scheme for your variable names that describes these probabilities so that a) you understand what they mean; and b) the others (including your grader) will understand those!\n",
    "\n",
    "Hint: you may get some ideas from the Python notes, Section 2.3 Base Language.\n",
    "\n",
    "The first task is to compute these probabilities. Use only training data for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809bbd22-51ac-4aa7-9a76-d395fc71c92d",
   "metadata": {},
   "source": [
    "Vairable name for spam/not spam: Pr_S1, Pr_S0\n",
    "\n",
    "Vairable name for spam email with the spam word: Pr_S1W1\n",
    "\n",
    "Vairable name for non-spam email with the spam word: Pr_S0W1\n",
    "\n",
    "Vairable name for spam email without the spam word: Pr_S1W0\n",
    "\n",
    "Vairable name for non-spam email without the spam word: Pr_S0W0\n",
    "\n",
    "Vairable name for probability of the spam word is marked as spam: Pr_W1S1\n",
    "    \n",
    "Vairable name for probability of the spam word is not marked as spam: Pr_W1S0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a7e429-020d-4f62-a477-abd528057531",
   "metadata": {},
   "source": [
    "#### 2. Compute the priors, the unconditional probabilities for an email being spam and non-spam, Pr(category = S) and Pr(category = NS). These probabilities are based on the spam variable alone, not on the text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa479cba-fa9b-4d7c-93d6-441ede7b65c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of being spam in training data 0.165\n",
      "Probability of being not spam in training data 0.835\n"
     ]
    }
   ],
   "source": [
    "Pr_S1 = train_y.mean()\n",
    "Pr_S0 = 1 - train_y.mean()\n",
    "print(\"Probability of being spam in training data\", round(Pr_S1, 3))\n",
    "print(\"Probability of being not spam in training data\", round(Pr_S0, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3101d14-bbcf-424e-bf9c-db131694b5f6",
   "metadata": {},
   "source": [
    "#### 3. For each word w, compute the normalizers, Pr(w = 1) and Pr(w = 0).\n",
    "\n",
    "Hint: this is Pr(million = 1) = 0.0484. But note this value (and the following hints) depends on\n",
    "your random training/validation split!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbcfaf95-5f78-405f-8ea2-162146dd8eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pr( viagra = 1): 0.0\n",
      "Pr( viagra = 0): 1.0\n",
      "Pr( deadline = 1): 0.153\n",
      "Pr( deadline = 0): 0.847\n",
      "Pr( million = 1): 0.048\n",
      "Pr( million = 0): 0.952\n",
      "Pr( and = 1): 0.942\n",
      "Pr( and = 0): 0.058\n",
      "Pr( toll = 1): 0.019\n",
      "Pr( toll = 0): 0.981\n",
      "Pr( prizes = 1): 0.008\n",
      "Pr( prizes = 0): 0.992\n",
      "Pr( cash = 1): 0.036\n",
      "Pr( cash = 0): 0.964\n",
      "Pr( insurance = 1): 0.009\n",
      "Pr( insurance = 0): 0.991\n",
      "Pr( free = 1): 0.184\n",
      "Pr( free = 0): 0.816\n",
      "Pr( money = 1): 0.084\n",
      "Pr( money = 0): 0.916\n"
     ]
    }
   ],
   "source": [
    "for word in list_of_words: \n",
    "    Pr_W1 = np.mean(train_X[word])\n",
    "    Pr_W0 = 1 - Pr_W1\n",
    "    \n",
    "    print(\"Pr(\", word,\"= 1):\", round(Pr_W1, 3))\n",
    "    print(\"Pr(\", word,\"= 0):\", round(Pr_W0, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd0f5a2-aa9e-4bc7-8662-cb30de674cb7",
   "metadata": {},
   "source": [
    "#### 4. For each word w, compute Pr(w = 1|category = S) and Pr(w = 1|category = NS). These probabilities are based on both the spam-variable and on the DTM component that corresponds to the word w.\n",
    "\n",
    "Hint: Pr(million = 1|category = S) = 0.252\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6bda1a16-f3d9-4878-9940-b6d303c633f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pr( viagra = 1|category = S ): 0.003\n",
      "Pr( viagra = 1|category = NS ): 0.0\n",
      "Pr( deadline = 1|category = S ): 0.0\n",
      "Pr( deadline = 1|category = NS ): 0.184\n",
      "Pr( million = 1|category = S ): 0.241\n",
      "Pr( million = 1|category = NS ): 0.01\n",
      "Pr( and = 1|category = S ): 0.919\n",
      "Pr( and = 1|category = NS ): 0.946\n",
      "Pr( toll = 1|category = S ): 0.1\n",
      "Pr( toll = 1|category = NS ): 0.004\n",
      "Pr( prizes = 1|category = S ): 0.042\n",
      "Pr( prizes = 1|category = NS ): 0.001\n",
      "Pr( cash = 1|category = S ): 0.163\n",
      "Pr( cash = 1|category = NS ): 0.011\n",
      "Pr( insurance = 1|category = S ): 0.034\n",
      "Pr( insurance = 1|category = NS ): 0.004\n",
      "Pr( free = 1|category = S ): 0.622\n",
      "Pr( free = 1|category = NS ): 0.097\n",
      "Pr( money = 1|category = S ): 0.362\n",
      "Pr( money = 1|category = NS ): 0.029\n"
     ]
    }
   ],
   "source": [
    "for word in list_of_words:\n",
    "    \n",
    "    temp = train_X.copy()\n",
    "    temp[\"spam\"] = train_y\n",
    "    \n",
    "    Pr_W1S1 = temp[temp.spam == 1]\n",
    "    Pr_W1S1 = Pr_W1S1[word].mean()\n",
    "    \n",
    "    Pr_W1S0 = temp[temp.spam == 0]\n",
    "    Pr_W1S0 = Pr_W1S0[word].mean()\n",
    "    \n",
    "    print(\"Pr(\", word, \"= 1|category = S ):\", round(Pr_W1S1, 3))\n",
    "    print(\"Pr(\", word, \"= 1|category = NS ):\", round(Pr_W1S0, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e468f794-d425-48ef-8476-c4203409c2a0",
   "metadata": {},
   "source": [
    "#### 5. Finally, compute the probabilities of interest, Pr(category = S|w = 1) and Pr(category = S|w = 0). Compute this value using Bayes theorem, not directly by counting! For the check, you may also compute Pr(category = NS|w = 1) and Pr(category = NS|w = 0)\n",
    "\n",
    "Hint: Pr(category = S|million = 1) = 0.843. But note this number depends on your random\n",
    "testing-validation split!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bbc1427f-d436-475f-94a0-1c977471ddd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pr(category = S | viagra  = 1) =  1.0\n",
      "Pr(category = S | viagra  = 0) =  0.164\n",
      "Pr(category = NS | viagra  = 1) =  0.0\n",
      "Pr(category = NS | viagra  = 0) =  0.836\n",
      "Pr(category = S | deadline  = 1) =  0.0\n",
      "Pr(category = S | deadline  = 0) =  0.194\n",
      "Pr(category = NS | deadline  = 1) =  1.0\n",
      "Pr(category = NS | deadline  = 0) =  0.806\n",
      "Pr(category = S | million  = 1) =  0.821\n",
      "Pr(category = S | million  = 0) =  0.131\n",
      "Pr(category = NS | million  = 1) =  0.179\n",
      "Pr(category = NS | million  = 0) =  0.869\n",
      "Pr(category = S | and  = 1) =  0.161\n",
      "Pr(category = S | and  = 0) =  0.23\n",
      "Pr(category = NS | and  = 1) =  0.839\n",
      "Pr(category = NS | and  = 0) =  0.77\n",
      "Pr(category = S | toll  = 1) =  0.844\n",
      "Pr(category = S | toll  = 0) =  0.151\n",
      "Pr(category = NS | toll  = 1) =  0.156\n",
      "Pr(category = NS | toll  = 0) =  0.849\n",
      "Pr(category = S | prizes  = 1) =  0.889\n",
      "Pr(category = S | prizes  = 0) =  0.159\n",
      "Pr(category = NS | prizes  = 1) =  0.111\n",
      "Pr(category = NS | prizes  = 0) =  0.841\n",
      "Pr(category = S | cash  = 1) =  0.747\n",
      "Pr(category = S | cash  = 0) =  0.143\n",
      "Pr(category = NS | cash  = 1) =  0.253\n",
      "Pr(category = NS | cash  = 0) =  0.857\n",
      "Pr(category = S | insurance  = 1) =  0.65\n",
      "Pr(category = S | insurance  = 0) =  0.16\n",
      "Pr(category = NS | insurance  = 1) =  0.35\n",
      "Pr(category = NS | insurance  = 0) =  0.84\n",
      "Pr(category = S | free  = 1) =  0.558\n",
      "Pr(category = S | free  = 0) =  0.076\n",
      "Pr(category = NS | free  = 1) =  0.442\n",
      "Pr(category = NS | free  = 0) =  0.924\n",
      "Pr(category = S | money  = 1) =  0.708\n",
      "Pr(category = S | money  = 0) =  0.115\n",
      "Pr(category = NS | money  = 1) =  0.292\n",
      "Pr(category = NS | money  = 0) =  0.885\n"
     ]
    }
   ],
   "source": [
    "for word in list_of_words:\n",
    "    Pr_W1 = np.mean(train_X[word])\n",
    "    Pr_W0 = 1 - Pr_W1\n",
    "    \n",
    "    temp = train_X.copy()\n",
    "    temp[\"spam\"] = train_y\n",
    "    \n",
    "    Pr_W1S1 = temp[temp.spam == 1]\n",
    "    Pr_W1S1 = Pr_W1S1[word].mean()\n",
    "    \n",
    "    Pr_W1S0 = temp[temp.spam == 0]\n",
    "    Pr_W1S0 = Pr_W1S0[word].mean()\n",
    "    \n",
    "    Pr_W0S1 = 1 - Pr_W1S1\n",
    "    Pr_W0S0 = 1 - Pr_W1S0\n",
    "        \n",
    "    Pr_S1W1 = (Pr_W1S1 * Pr_S1) / Pr_W1\n",
    "    Pr_S1W0 = (Pr_W0S1 * Pr_S1) / Pr_W0\n",
    "    \n",
    "    Pr_S0W1 = (Pr_W1S0 * Pr_S0) / Pr_W1\n",
    "    Pr_S0W0 = (Pr_W0S0 * Pr_S0) / Pr_W0\n",
    "        \n",
    "    print(\"Pr(category = S |\", word, \" = 1) = \", round(Pr_S1W1, 3))\n",
    "    print(\"Pr(category = S |\", word, \" = 0) = \", round(Pr_S1W0, 3))\n",
    "\n",
    "    print(\"Pr(category = NS |\", word, \" = 1) = \", round(Pr_S0W1, 3))\n",
    "    print(\"Pr(category = NS |\", word, \" = 0) = \", round(Pr_S0W0, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243c44df-a10f-4406-a2aa-4db9a295f88d",
   "metadata": {},
   "source": [
    "#### 6. Which of these probabilities have to sum to one? (E.g. Pr(category = 1) +Pr(category = 0) = 1.) Which ones do not? Explain!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4919ae97-5123-4b71-b8e8-8de9767b2a8b",
   "metadata": {},
   "source": [
    "Each of the 10 words have 4 different Pr, and the pairs that have W = 1 (so when the word is present in the email) sum to one and for the pairs that have W = 0 (so when the word is not present) sum to one as well. \n",
    "\n",
    "For example: \n",
    "\n",
    "Pr(category = S | money  = 1) + Pr(category = NS | money  = 1) = (0.72 + 0.28) = 1\n",
    "\n",
    "Pr(category = S | money  = 0) + Pr(category = NS | money  = 0) = (0.112 + 0.888) = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d226e25a-1bff-4454-9714-48b594fece16",
   "metadata": {},
   "source": [
    "#### 7. For each email in your validation set, predict whether it is predicted to be spam or nonspam. Hint: you should check if it contains the word w and use the appropriate probability, Pr(category = S|w = 1) or Pr(category = S|w = 0).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d94640a1-5184-40cf-a569-5bc3b592b339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "viagra\n",
      "[[479   0]\n",
      " [100   0]]\n",
      "Accuracy:  0.827\n",
      "Precision:  0.0\n",
      "Recall:  0.0\n",
      "\n",
      "deadline\n",
      "[[479   0]\n",
      " [100   0]]\n",
      "Accuracy:  0.827\n",
      "Precision:  0.0\n",
      "Recall:  0.0\n",
      "\n",
      "million\n",
      "[[475   4]\n",
      " [ 76  24]]\n",
      "Accuracy:  0.862\n",
      "Precision:  0.857\n",
      "Recall:  0.24\n",
      "\n",
      "and\n",
      "[[479   0]\n",
      " [100   0]]\n",
      "Accuracy:  0.827\n",
      "Precision:  0.0\n",
      "Recall:  0.0\n",
      "\n",
      "toll\n",
      "[[479   0]\n",
      " [ 86  14]]\n",
      "Accuracy:  0.851\n",
      "Precision:  1.0\n",
      "Recall:  0.14\n",
      "\n",
      "prizes\n",
      "[[478   1]\n",
      " [ 96   4]]\n",
      "Accuracy:  0.832\n",
      "Precision:  0.8\n",
      "Recall:  0.04\n",
      "\n",
      "cash\n",
      "[[466  13]\n",
      " [ 72  28]]\n",
      "Accuracy:  0.853\n",
      "Precision:  0.683\n",
      "Recall:  0.28\n",
      "\n",
      "insurance\n",
      "[[477   2]\n",
      " [ 98   2]]\n",
      "Accuracy:  0.827\n",
      "Precision:  0.5\n",
      "Recall:  0.02\n",
      "\n",
      "free\n",
      "[[446  33]\n",
      " [ 39  61]]\n",
      "Accuracy:  0.876\n",
      "Precision:  0.649\n",
      "Recall:  0.61\n",
      "\n",
      "money\n",
      "[[469  10]\n",
      " [ 58  42]]\n",
      "Accuracy:  0.883\n",
      "Precision:  0.808\n",
      "Recall:  0.42\n"
     ]
    }
   ],
   "source": [
    "for words in list_of_words:\n",
    "    Pr_W1 = np.mean(train_X[words])\n",
    "    Pr_W0 = 1 - Pr_W1\n",
    "    \n",
    "    temp = train_X.copy()\n",
    "    temp[\"spam\"] = train_y\n",
    "    \n",
    "    Pr_W1S1 = temp[temp.spam == 1]\n",
    "    Pr_W1S1 = Pr_W1S1[words].mean()\n",
    "    \n",
    "    Pr_W1S0 = temp[temp.spam == 0]\n",
    "    Pr_W1S0 = Pr_W1S0[word].mean()\n",
    "    \n",
    "    Pr_W0S1 = 1 - Pr_W1S1\n",
    "    Pr_W0S0 = 1 - Pr_W1S0\n",
    "    \n",
    "    predict = []\n",
    "    \n",
    "    for index, row in test_X.iterrows():\n",
    "        if row[words] == 1:    # w = 1\n",
    "            Pr_S1W1 = (Pr_W1S1 * Pr_S1) / Pr_W1\n",
    "            \n",
    "            if Pr_S1W1 > 0.5: # when it is spam\n",
    "                predict.append(1)\n",
    "            else:\n",
    "                predict.append(0)\n",
    "        elif row[words] == 0: \n",
    "            Pr_S1W0 = (Pr_W0S1 * Pr_S1) / Pr_W0\n",
    "            \n",
    "            if Pr_S1W0 > 0.5: # when it is spam\n",
    "                predict.append(1)\n",
    "            else:\n",
    "                predict.append(0)\n",
    "\n",
    "    cm = confusion_matrix(test_y, predict)\n",
    "    print(\"\\n\" + words)\n",
    "    print(cm)\n",
    "    \n",
    "    print(\"Accuracy: \", round(np.mean(test_y == predict),3)) #accuracy\n",
    "\n",
    "    from sklearn.metrics import precision_score\n",
    "    print(\"Precision: \", round(precision_score(test_y, predict, zero_division = 0),3)) #precision\n",
    "\n",
    "    from sklearn.metrics import recall_score\n",
    "    print(\"Recall: \", round(recall_score(test_y, predict),3)) #recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0143cc-9568-4082-957c-27fed611af5d",
   "metadata": {},
   "source": [
    "#### 8. Print the resulting confusion matrix and compute accuracy, precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fb4f4e-f4ab-4549-a56b-059a5d019cff",
   "metadata": {},
   "source": [
    "Each confusion matrix for each word is above, and the resulting accurate, precison, and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c701cb-8d46-418c-af63-e95989dc1561",
   "metadata": {},
   "source": [
    "#### 9. Which steps above constitute model training? In which steps do you use trained model? What is a trained model in this case? Explain!\n",
    "\n",
    "Hint: a trained model is all you need to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9888296-8f9e-40c3-9514-987210a2b7c7",
   "metadata": {},
   "source": [
    "Step 7 uses model training to calculate the different probablities that a word will be spam or not. From there we no longer need the training data, as we only need to know which probability is over our set threshold to determine if the email is spam or not. Train_X is the trained model, as it is the set of emails we use to calcuate probaility and determine our predictions of whether train_X emails are spam or not. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b58dbf-7aa3-4965-8982-a955d0e458fc",
   "metadata": {},
   "source": [
    "#### 10. Comment the overall performance of the model–how do accuracy, precision and recall look like?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b75563-bf4c-4371-ae78-d50bce5a69aa",
   "metadata": {},
   "source": [
    "We determined that if more than 5 of the words were determined to be part of a spam email, then the email is spam email (not spam otherwise). Our accuracy is relatively high, at 83.9%, our precision was also high at 94.1%, and our recall is at 14.8%, which is similar to the original percentage of spam emails in our test data (19.7%). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a44c66-714a-475b-b4b1-23ab56f93c60",
   "metadata": {},
   "source": [
    "#### 11. Explain why do you see very low recall while the other indicators do not look that bad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a99512-912d-4695-b34a-966d32436b96",
   "metadata": {},
   "source": [
    "Somewhat explained above, recall is the relative amount of posititve results in the data. Our positive result is spam emails, which only consist of 19.7% of the test data, so an accurate model would show a percent close to this percent, if it had predicted a similar relative percent of spam emails."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae18bb78-c413-43fc-a154-94e15e37d063",
   "metadata": {},
   "source": [
    "#### 12. Explain why some words work well and others not:\n",
    "\n",
    "(a) why does “million” improve accuracy?\n",
    "\n",
    "Million improves accuracy as it is a word that commonly appears in spam emails and less often in regular emails. The word 'million' is not likely to be used in a professional setting, and is often used as bait to get the victim to click on the email.\n",
    "\n",
    "(b) why does “viagra” not work?\n",
    "\n",
    "Viagra does not work very well because the frequency of it in the whole data frame is very low, so the training data almost always never has any/enough emails for it to be a work to accurately identify spam emails.\n",
    "\n",
    "(c) why does “deadline” not work?\n",
    "\n",
    "Deadline does not work as well as there are many more emails that use the word 'deadline' that are not spam emails than emails that are spam and use the word deadline. For example, the word 'deadline' is likely to be used in conversations between colleagues when discussing work. But in this case specifically, there is no deadline word in the training set for spam emails. \n",
    "\n",
    "(d) why does “and” not work?\n",
    "\n",
    "And is a word that is frequently used in both spam non-spam emails, so it is not a good word to identify spam emails with and will be commonly misidentified both ways. \n",
    "\n",
    "Hint: You may just see where in which emails these words occur, and how frequently. These are all\n",
    "different reasons!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ff05af-02f9-48d7-a0ea-dc948d8a25cf",
   "metadata": {},
   "source": [
    "#### 13. Add such smoothing to the model. You can either literally add two such lines of data, or alternatively manipulate the way you compute the probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "edccf3e8-b63e-4dae-9779-257223caae48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pr(category = S | viagra  = 1) =  0.51\n",
      "Pr(category = S | viagra  = 0) =  0.444\n",
      "Pr(category = NS | viagra  = 1) =  0.504\n",
      "Pr(category = NS | viagra  = 0) =  0.544\n",
      "Pr(category = S | deadline  = 1) =  0.497\n",
      "Pr(category = S | deadline  = 0) =  0.454\n",
      "Pr(category = NS | deadline  = 1) =  0.492\n",
      "Pr(category = NS | deadline  = 0) =  0.557\n",
      "Pr(category = S | million  = 1) =  0.506\n",
      "Pr(category = S | million  = 0) =  0.447\n",
      "Pr(category = NS | million  = 1) =  0.5\n",
      "Pr(category = NS | million  = 0) =  0.548\n",
      "Pr(category = S | and  = 1) =  0.441\n",
      "Pr(category = S | and  = 0) =  0.513\n",
      "Pr(category = NS | and  = 1) =  0.436\n",
      "Pr(category = NS | and  = 0) =  0.629\n",
      "Pr(category = S | toll  = 1) =  0.508\n",
      "Pr(category = S | toll  = 0) =  0.445\n",
      "Pr(category = NS | toll  = 1) =  0.502\n",
      "Pr(category = NS | toll  = 0) =  0.546\n",
      "Pr(category = S | prizes  = 1) =  0.509\n",
      "Pr(category = S | prizes  = 0) =  0.444\n",
      "Pr(category = NS | prizes  = 1) =  0.503\n",
      "Pr(category = NS | prizes  = 0) =  0.545\n",
      "Pr(category = S | cash  = 1) =  0.507\n",
      "Pr(category = S | cash  = 0) =  0.446\n",
      "Pr(category = NS | cash  = 1) =  0.501\n",
      "Pr(category = NS | cash  = 0) =  0.547\n",
      "Pr(category = S | insurance  = 1) =  0.509\n",
      "Pr(category = S | insurance  = 0) =  0.444\n",
      "Pr(category = NS | insurance  = 1) =  0.503\n",
      "Pr(category = NS | insurance  = 0) =  0.545\n",
      "Pr(category = S | free  = 1) =  0.495\n",
      "Pr(category = S | free  = 0) =  0.456\n",
      "Pr(category = NS | free  = 1) =  0.489\n",
      "Pr(category = NS | free  = 0) =  0.559\n",
      "Pr(category = S | money  = 1) =  0.503\n",
      "Pr(category = S | money  = 0) =  0.449\n",
      "Pr(category = NS | money  = 1) =  0.497\n",
      "Pr(category = NS | money  = 0) =  0.551\n"
     ]
    }
   ],
   "source": [
    "alpha = 3\n",
    "\n",
    "for word in list_of_words:\n",
    "    Pr_W1 = np.mean(train_X[word])\n",
    "    Pr_W0 = 1 - Pr_W1\n",
    "    \n",
    "    temp = train_X.copy()\n",
    "    temp[\"spam\"] = train_y\n",
    "    \n",
    "    spam_temp = temp[temp.spam == 1]\n",
    "    Pr_W1S1 = spam_temp[spam_temp == 1].count()\n",
    "    Pr_W1S1 = (Pr_W1S1[words]) / (len(spam_temp))\n",
    "    \n",
    "    nospam_temp = temp[temp.spam == 0]\n",
    "    Pr_W1S0 = nospam_temp[nospam_temp == 1].count()\n",
    "    Pr_W1S0 = (Pr_W1S0[words]) / (len(nospam_temp))\n",
    "    \n",
    "    Pr_W0S1 = 1 - Pr_W1S1\n",
    "    Pr_W0S0 = 1 - Pr_W1S0\n",
    "        \n",
    "    Pr_S1W1 = ((Pr_W1S1 * Pr_S1) + alpha) / (Pr_W1 + 2*alpha)\n",
    "    Pr_S1W0 = ((Pr_W0S1 * Pr_S1) + alpha) / (Pr_W0 + 2*alpha)\n",
    "    \n",
    "    Pr_S0W1 = ((Pr_W1S0 * Pr_S0) + alpha) / (Pr_W1 + 2*alpha)\n",
    "    Pr_S0W0 = ((Pr_W0S0 * Pr_S0) + alpha) / (Pr_W0 + 2*alpha)\n",
    "        \n",
    "    print(\"Pr(category = S |\", word, \" = 1) = \", round(Pr_S1W1, 3))\n",
    "    print(\"Pr(category = S |\", word, \" = 0) = \", round(Pr_S1W0, 3))\n",
    "\n",
    "    print(\"Pr(category = NS |\", word, \" = 1) = \", round(Pr_S0W1, 3))\n",
    "    print(\"Pr(category = NS |\", word, \" = 0) = \", round(Pr_S0W0, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f97a72-50ed-45a9-b0ef-03074f85b631",
   "metadata": {},
   "source": [
    "#### 14. Repeat the tasks above: compute the probabilities, do predictions, compute the accuracy, precision, recall for all words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a8fa478-f0b1-4c11-a3d7-77c5ef202eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "viagra\n",
      "[[479   0]\n",
      " [100   0]]\n",
      "Accuracy:  0.827\n",
      "Precision:  0.0\n",
      "Recall:  0.0\n",
      "\n",
      "deadline\n",
      "[[479   0]\n",
      " [100   0]]\n",
      "Accuracy:  0.827\n",
      "Precision:  0.0\n",
      "Recall:  0.0\n",
      "\n",
      "million\n",
      "[[475   4]\n",
      " [ 76  24]]\n",
      "Accuracy:  0.862\n",
      "Precision:  0.857\n",
      "Recall:  0.24\n",
      "\n",
      "and\n",
      "[[479   0]\n",
      " [100   0]]\n",
      "Accuracy:  0.827\n",
      "Precision:  0.0\n",
      "Recall:  0.0\n",
      "\n",
      "toll\n",
      "[[479   0]\n",
      " [ 86  14]]\n",
      "Accuracy:  0.851\n",
      "Precision:  1.0\n",
      "Recall:  0.14\n",
      "\n",
      "prizes\n",
      "[[478   1]\n",
      " [ 96   4]]\n",
      "Accuracy:  0.832\n",
      "Precision:  0.8\n",
      "Recall:  0.04\n",
      "\n",
      "cash\n",
      "[[466  13]\n",
      " [ 72  28]]\n",
      "Accuracy:  0.853\n",
      "Precision:  0.683\n",
      "Recall:  0.28\n",
      "\n",
      "insurance\n",
      "[[477   2]\n",
      " [ 98   2]]\n",
      "Accuracy:  0.827\n",
      "Precision:  0.5\n",
      "Recall:  0.02\n",
      "\n",
      "free\n",
      "[[446  33]\n",
      " [ 39  61]]\n",
      "Accuracy:  0.876\n",
      "Precision:  0.649\n",
      "Recall:  0.61\n",
      "\n",
      "money\n",
      "[[469  10]\n",
      " [ 58  42]]\n",
      "Accuracy:  0.883\n",
      "Precision:  0.808\n",
      "Recall:  0.42\n"
     ]
    }
   ],
   "source": [
    "alpha = 3\n",
    "\n",
    "for words in list_of_words:\n",
    "    Pr_W1 = np.mean(train_X[words])\n",
    "    Pr_W0 = 1 - Pr_W1\n",
    "    \n",
    "    temp = train_X.copy()\n",
    "    temp[\"spam\"] = train_y\n",
    "    \n",
    "    spam_temp = temp[temp.spam == 1]\n",
    "    Pr_W1S1 = spam_temp[spam_temp == 1].count()\n",
    "    Pr_W1S1 = (Pr_W1S1[words]) / (len(spam_temp))\n",
    "    \n",
    "    nospam_temp = temp[temp.spam == 0]\n",
    "    Pr_W1S0 = nospam_temp[nospam_temp == 1].count()\n",
    "    Pr_W1S0 = (Pr_W1S0[words]) / (len(nospam_temp))\n",
    "    \n",
    "    Pr_W0S1 = 1 - Pr_W1S1\n",
    "    Pr_W0S0 = 1 - Pr_W1S0\n",
    "    \n",
    "    predict = []\n",
    "    \n",
    "    for index, row in test_X.iterrows():\n",
    "        if row[words] == 1:    # w = 1\n",
    "            Pr_S1W1 = ((Pr_W1S1 * Pr_S1) + alpha) / (Pr_W1 + 2*alpha)\n",
    "            #Pr_S1W1 = (Pr_W1S1 * Pr_S1) / Pr_W1\n",
    "            #print(Pr_S1W1)\n",
    "            \n",
    "            if Pr_S1W1 > 0.5: # when it is spam\n",
    "                predict.append(1)\n",
    "            else:\n",
    "                predict.append(0)\n",
    "        elif row[words] == 0: \n",
    "            Pr_S1W0 = ((Pr_W0S1 * Pr_S1) + alpha) / (Pr_W0 + 2*alpha)\n",
    "            #Pr_S1W0 = (Pr_W0S1 * Pr_S1) / Pr_W0\n",
    "            #print(Pr_S1W0)\n",
    "            \n",
    "            if Pr_S1W0 > 0.5: # when it is spam\n",
    "                predict.append(1)\n",
    "            else:\n",
    "                predict.append(0)\n",
    "\n",
    "    cm = confusion_matrix(test_y, predict)\n",
    "    print(\"\\n\" + words)\n",
    "    print(cm)\n",
    "    \n",
    "    print(\"Accuracy: \", round(np.mean(test_y == predict),3)) #accuracy\n",
    "\n",
    "    from sklearn.metrics import precision_score\n",
    "    print(\"Precision: \", round(precision_score(test_y, predict, zero_division = 0),3)) #precision\n",
    "\n",
    "    from sklearn.metrics import recall_score\n",
    "    print(\"Recall: \", round(recall_score(test_y, predict),3)) #recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c7a634-d604-47de-bcb9-2c672c1aec02",
   "metadata": {},
   "source": [
    "#### 15. Comment on the results. Does smoothing improve the overall performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fafc9c4-becc-4dc0-b9ac-29f976861c65",
   "metadata": {},
   "source": [
    "Smoothing does not change the overall performance of accuracy, precision, and recall, even if we increase the value of alpha. We believe that this smoothing is not making a great enough change in the data to change any of the predictions. However, if we look at the probalites in 13, and we see that as alpha increases, the probabilties become closer to 50% (again, because of our threshold, though the proabilites are becoming more smaller in differences, those that were greater than out threshold are still greater so the predictions do not change)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
